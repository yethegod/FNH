{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981d0804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe4b41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import matplotlib\n",
    "# matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import random\n",
    "\n",
    "\n",
    "from datetime import timedelta\n",
    "import scipy.stats\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import copy\n",
    "\n",
    "from scipy.interpolate import splev, splrep, interp1d\n",
    "\n",
    "import sklearn\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from torchdiffeq import odeint_adjoint as odeint_adjoint\n",
    "from torchdiffeq import odeint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c038130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adaptive_select import create_adap_data_buffer\n",
    "from interpolate_windows import interpolate_window, interpolate_window_adap\n",
    "from RNN_ODE_functions import fit_non_adap_models_grids, pred_non_adap_models_grids, train_non_adap_models\n",
    "from RNN_ODE_Adap_functions import fit_adap_models, pred_adap_models, train_adap_models\n",
    "from network import RNNODE, OutputNN\n",
    "\n",
    "import data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16c1146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88ef5c8",
   "metadata": {},
   "source": [
    "## generate training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c1e661",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,_ = data.get_data(128)\n",
    "valid_x,_ = data.get_data(128)\n",
    "test_x,_ = data.get_data(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5062614",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_fine_grid = 1000\n",
    "num_layers = 3\n",
    "num_coarse_grid = num_fine_grid // 2**(num_layers-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32t0a6xm2yj",
   "metadata": {},
   "source": [
    "## RNN-ODE One-Step Prediction Experiment (N=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7h55yyx31x3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters for RNN-ODE\n",
    "# num_grids = 65  # N=64, so num_grids = N+1 = 65\n",
    "num_grids = 500\n",
    "verbose = 2\n",
    "method = \"naiveEuler\"\n",
    "n_iter = 400\n",
    "batch_size = 64\n",
    "obs_dim = 1\n",
    "n_hidden = 128\n",
    "n_latent = 128\n",
    "rescale_const = 1.\n",
    "time_scale = 10\n",
    "buffer_start_steps = 2\n",
    "\n",
    "print(f\"Experiment Configuration:\")\n",
    "print(f\"Window length (N): {num_fine_grid}\")\n",
    "print(f\"Number of grids: {num_grids}\")\n",
    "print(f\"Method: {method}\")\n",
    "print(f\"Iterations: {n_iter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i0b1s3mtef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage for testing RMSE results\n",
    "testing_rmse_list = []\n",
    "\n",
    "print(\"Starting RNN-ODE One-Step Prediction Experiment...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Run experiment for each repetition - following spiral_example structure\n",
    "rep = 0\n",
    "while rep < num_rep:\n",
    "    print(f\"\\n------the {rep+1}-th replica:--------\")\n",
    "    \n",
    "    # Get training and testing data for this repetition\n",
    "    train_windows0 = train_windows0_list[rep]\n",
    "    train_ts0 = train_ts0_list[rep]\n",
    "    test_windows0 = test_windows0_list[rep]\n",
    "    test_ts0 = test_ts0_list[rep]\n",
    "    \n",
    "    valid_index = np.sort(npr.choice(train_windows0.shape[0], 50, replace=False))\n",
    "    valid_windows0 = train_windows0[valid_index, :, :]\n",
    "    valid_ts0 = train_ts0[valid_index, :]\n",
    "    \n",
    "    # Create validation set - exactly like spiral_example\n",
    "    train_index = np.delete(np.arange(train_windows0.shape[0]), valid_index)\n",
    "    train_windows1 = train_windows0[train_index, :, :].clone()\n",
    "    train_ts1 = train_ts0[train_index, :].clone()\n",
    "    \n",
    "    # Add buffer steps like in spiral_example\n",
    "    if buffer_start_steps > 0:\n",
    "        deltat = train_ts1[0][-1] - train_ts1[0][-2]\n",
    "        train_ts1[:,:buffer_start_steps] = (train_ts1[:,:buffer_start_steps] + \n",
    "                                           torch.arange(-deltat*buffer_start_steps, 0, deltat))\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    train_dataset1 = MyDataset(train_windows1, train_ts1)\n",
    "    train_loader1 = DataLoader(train_dataset1, shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    input_steps1 = train_windows1.shape[1]\n",
    "    \n",
    "    # Train RNN-ODE model - exact parameters from spiral_example\n",
    "    flag, odefunc1, outputfunc1 = train_non_adap_models(\n",
    "        train_loader1, input_steps1, valid_windows0, valid_ts0, num_grids,  \n",
    "        verbose, n_iter=n_iter, method=method, thres1=6.5e2, thres2=6.5e2, weight=(1,0),        \n",
    "        obs_dim=obs_dim, n_hidden=n_hidden, n_latent=n_latent, num_train_windows=len(train_index), \n",
    "        time_scale=time_scale, buffer_start_steps=buffer_start_steps\n",
    "    )\n",
    "\n",
    "    if not flag:\n",
    "        print(f\"Training failed for repetition {rep+1}, skipping...\")\n",
    "        continue\n",
    "    else:\n",
    "        rep += 1\n",
    "        print(f\"Training successful for repetition {rep}\")\n",
    "    \n",
    "    # Evaluate standard one-step prediction (RMSE from fit_non_adap_models_grids)\n",
    "    print('\\\\nfitting error of testing data:')\n",
    "    _, fit_L2_err_test1, _ = fit_non_adap_models_grids(\n",
    "        odefunc1, outputfunc1, test_windows0, test_ts0, num_grids, method=method,\n",
    "        buffer_start_steps=buffer_start_steps, n_latent=n_latent, obs_dim=obs_dim,\n",
    "        rescale_const=rescale_const, time_scale=time_scale\n",
    "    ) # this is RMSE\n",
    "    \n",
    "    \n",
    "    # Store results\n",
    "    testing_rmse = fit_L2_err_test1.mean().item()  # This is RMSE\n",
    "    testing_rmse_list.append(testing_rmse)\n",
    "    \n",
    "    print(f\"Testing RMSE: {testing_rmse:.6f}\")\n",
    "\n",
    "print(f\"\\\\n\" + \"=\"*60)\n",
    "print(f\"EXPERIMENT COMPLETED\")\n",
    "print(f\"=\"*60)\n",
    "print(f\"Successful repetitions: {len(testing_rmse_list)}/{num_rep}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hts74jn1qs",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Display final results\n",
    "if len(testing_rmse_list) > 0:\n",
    "    testing_rmse_array = np.array(testing_rmse_list)\n",
    "    testing_mse_array = testing_rmse_array ** 2\n",
    "        \n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*60)\n",
    "    print(\"RNN-ODE ONE-STEP PREDICTION RESULTS (N=64)\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Successful repetitions: {len(testing_rmse_array)}/{num_rep}\")\n",
    "    print(f\"Success rate: {len(testing_rmse_array)/num_rep*100:.1f}%\")\n",
    "    print()\n",
    "    \n",
    "    print(\"TESTING L2-error RESULTS:\")\n",
    "    print(\"-\" * 35)\n",
    "    print(f\"Mean: {testing_rmse_array.mean():.6f}\")\n",
    "    print(f\"Std:  {testing_rmse_array.std():.6f}\")\n",
    "    print(f\"Min:  {testing_rmse_array.min():.6f}\")\n",
    "    print(f\"Max:  {testing_rmse_array.max():.6f}\")\n",
    "\n",
    "    \n",
    "    print()\n",
    "else:\n",
    "    print(\"\\\\nNo successful repetitions completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ec4b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run focused grid search to find optimal threshold\n",
    "print(\"=\"*60)\n",
    "print(\"FOCUSED THRESHOLD SEARCH (0.04 - 0.05)\")\n",
    "print(\"=\"*60)\n",
    "print(\"Searching in narrow range based on previous results...\")\n",
    "print()\n",
    "\n",
    "optimal_threshold_new, achieved_steps_new, search_results_new, valid_results_new = grid_search_threshold_updated(target_steps=43, tolerance=0.5)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(f\"FOCUSED GRID SEARCH RESULTS\")\n",
    "print(f\"=\"*50)\n",
    "print(f\"Optimal threshold: {optimal_threshold_new:.4f}\")\n",
    "print(f\"Achieved avg steps: {achieved_steps_new:.2f}\")\n",
    "print(f\"Target steps: 43\")\n",
    "print(f\"Search precision: 0.0001\")\n",
    "print(f\"Search range: [0.04, 0.05]\")\n",
    "print(f\"Total candidates tested: {len(search_results_new)}\")\n",
    "print(f\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1f7928",
   "metadata": {},
   "source": [
    "Using fine-grained grid search, the optimal threshold is 0.0398."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t5i2znpln4o",
   "metadata": {},
   "source": [
    "## RNN-ODE Adaptive One-Step Prediction Experiment (threshold=0.0358)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ad2ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptive RNN-ODE experiment parameters\n",
    "thres = 0.0358 # Optimal threshold found from grid search\n",
    "num_fine_adap = 64\n",
    "num_layers_adap = 3\n",
    "\n",
    "print(f\"RNN-ODE Adaptive One-Step Prediction Experiment\")\n",
    "print(f\"Threshold: {thres}\")\n",
    "print(f\"Fine grid: {num_fine_adap}\")\n",
    "print(f\"Layers: {num_layers_adap}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc12112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage for adaptive testing MSE results\n",
    "testing_rmse_adap_list = []\n",
    "num_grids_adap_list = []  # Track actual grid counts\n",
    "\n",
    "print(\"Starting RNN-ODE Adaptive One-Step Prediction Experiment...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Run experiment for each repetition\n",
    "rep = 0\n",
    "while rep < num_rep:\n",
    "    print(f\"\\n------Adaptive the {rep+1}-th replica:--------\")\n",
    "    \n",
    "    # Get training and testing data for this repetition\n",
    "    train_windows0 = train_windows0_list[rep]\n",
    "    train_ts0 = train_ts0_list[rep]\n",
    "    test_windows0 = test_windows0_list[rep]\n",
    "    test_ts0 = test_ts0_list[rep]\n",
    "    \n",
    "    valid_index = np.sort(npr.choice(train_windows0.shape[0], 50, replace=False))\n",
    "    train_index = np.delete(np.arange(train_windows0.shape[0]), valid_index)\n",
    "    \n",
    "    # Create adaptive data buffers - exactly like spiral_example\n",
    "    train_windows0_adap_buffer, train_ts0_adap_buffer, train_len0_adap_buffer, train_windows_adap_len = create_adap_data_buffer(\n",
    "        train_windows0, train_ts0, thres, num_fine_adap, num_layers_adap)\n",
    "    test_windows0_adap_buffer, test_ts0_adap_buffer, test_len0_adap_buffer, _ = create_adap_data_buffer(\n",
    "        test_windows0, test_ts0, thres, num_fine_adap, num_layers_adap)\n",
    "    \n",
    "    # train_windows, 1st half\n",
    "    train_windows0_adap_buffer_trunc, train_ts0_adap_buffer_trunc, _, _, train_time_index = create_adap_data_buffer(\n",
    "        train_windows0[:,:(train_ts0.shape[1]+1)//2,:], train_ts0[:,:(train_ts0.shape[1]+1)//2], thres, num_fine_adap//2, num_layers_adap, return_index=1)\n",
    "    # train_windows, 2nd half\n",
    "    _, train_ts0_adap_buffer_trunc2, train_len0_adap_buffer_trunc2, _ = create_adap_data_buffer(\n",
    "        train_windows0[:,-(train_ts0.shape[1]+1)//2:,:], train_ts0[:,-(train_ts0.shape[1]+1)//2:], thres, num_fine_adap//2, num_layers_adap, buffer_start_steps=0)\n",
    "    \n",
    "    num_grids_adap_list.append(train_windows_adap_len)\n",
    "    print(f'Adaptive method, thres = {thres:.4f}, number of grids = {train_windows_adap_len:.1f}')\n",
    "    \n",
    "    # Create validation set\n",
    "    valid_index = np.sort(npr.choice(train_windows0.shape[0], 50, replace=False))\n",
    "    valid_windows0 = train_windows0[valid_index,:,:]\n",
    "    valid_ts0 = train_ts0[valid_index,:]\n",
    "    \n",
    "    # Prepare adaptive validation data\n",
    "    valid_windows0_adap_buffer = train_windows0_adap_buffer[valid_index,:,:]\n",
    "    valid_ts0_adap_buffer = train_ts0_adap_buffer[valid_index,:]\n",
    "    valid_windows0_adap_buffer_trunc = train_windows0_adap_buffer_trunc[valid_index,:,:]\n",
    "    valid_ts0_adap_buffer_trunc = train_ts0_adap_buffer_trunc[valid_index,:]\n",
    "    \n",
    "    # Create second half data for prediction validation - exactly like spiral_example\n",
    "    valid_ts_adap_trunc2 = valid_ts0[:, (valid_ts0.shape[1]-1)//2::1]\n",
    "    valid_len_adap_trunc2 = [(valid_ts0.shape[1]-1)//2+1] * valid_windows0.shape[0]\n",
    "    \n",
    "    # Create adaptive dataset\n",
    "    train_dataset_adap = MyDataset_adap(train_windows0_adap_buffer, train_ts0_adap_buffer, train_len0_adap_buffer)\n",
    "    train_loader_adap = DataLoader(train_dataset_adap, shuffle=True, batch_size=batch_size)\n",
    "    \n",
    "    input_steps_adap = train_windows0_adap_buffer.shape[1]\n",
    "    \n",
    "    # Train adaptive RNN-ODE model - follow spiral_example parameters exactly\n",
    "    flag, odefunc_adap, outputfunc_adap = train_adap_models(\n",
    "        train_loader_adap, input_steps_adap, verbose,\n",
    "        valid_window=valid_windows0, valid_ts=valid_ts0, \n",
    "        valid_window_adap=valid_windows0_adap_buffer, valid_ts_adap=valid_ts0_adap_buffer,\n",
    "        valid_window_adap_trunc=valid_windows0_adap_buffer_trunc, valid_ts_adap_trunc=valid_ts0_adap_buffer_trunc,\n",
    "        buffer_start_steps=buffer_start_steps,\n",
    "        weight=(1,0), n_iter=n_iter, thres1=1.5e3, \n",
    "        valid_len=np.array(train_len0_adap_buffer)[valid_index],\n",
    "        valid_ts_adap_trunc2=valid_ts_adap_trunc2, valid_len_adap_trunc2=valid_len_adap_trunc2,\n",
    "        pred_len=(train_ts0.shape[1]-1)//2, rescale_const=rescale_const,  \n",
    "        n_latent=n_latent, obs_dim=obs_dim, time_scale=time_scale\n",
    "    )\n",
    "    \n",
    "    if not flag:\n",
    "        continue\n",
    "    else:\n",
    "        rep += 1\n",
    "        print(f\"Adaptive training successful for repetition {rep}\")\n",
    "    \n",
    "    # Evaluate adaptive one-step prediction using fitting function - exactly like spiral_example\n",
    "    interp_kind = 'cubic'\n",
    "    print('\\\\nAdaptive fitting error of testing data (cubic):')\n",
    "    _, fit_L2_err_adap_test, _ = fit_adap_models(\n",
    "        odefunc_adap, outputfunc_adap, test_windows0, test_ts0,\n",
    "        test_windows0_adap_buffer, test_ts0_adap_buffer, test_len0_adap_buffer, \n",
    "        buffer_start_steps, interp_kind=interp_kind, rescale_const=rescale_const, \n",
    "        n_latent=n_latent, obs_dim=obs_dim, time_scale=time_scale\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    testing_rmse_adap = (fit_L2_err_adap_test).mean().item()  # Convert RMSE to MSE\n",
    "    testing_rmse_adap_list.append(testing_rmse_adap)\n",
    "    \n",
    "    print(f\"Adaptive Testing RMSE: {testing_rmse_adap:.6f}\")\n",
    "\n",
    "print(f\"\\\\n\" + \"=\"*60)\n",
    "print(f\"ADAPTIVE EXPERIMENT COMPLETED\")\n",
    "print(f\"=\"*60)\n",
    "print(f\"Successful repetitions: {len(testing_rmse_adap_list)}/{num_rep}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd295e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display adaptive results and comparison\n",
    "if len(testing_rmse_adap_list) > 0:\n",
    "    testing_rmse_adap_array = np.array(testing_rmse_adap_list)\n",
    "    num_grids_adap_array = np.array(num_grids_adap_list)\n",
    "    \n",
    "    testing_mse_adap_array = testing_rmse_adap_array ** 2\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*60)\n",
    "    print(\"RNN-ODE ADAPTIVE ONE-STEP PREDICTION RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Successful repetitions: {len(testing_rmse_adap_array)}/{num_rep}\")\n",
    "    print(f\"Success rate: {len(testing_rmse_adap_array)/num_rep*100:.1f}%\")\n",
    "    print(f\"Average grid points: {num_grids_adap_array.mean():.1f} ± {num_grids_adap_array.std():.1f}\")\n",
    "    print()\n",
    "    \n",
    "    print(\"ADAPTIVE TESTING RMSE RESULTS:\")\n",
    "    print(\"-\" * 35)\n",
    "    print(f\"Mean: {testing_rmse_adap_array.mean():.6f}\")\n",
    "    print(f\"Std:  {testing_rmse_adap_array.std():.6f}\")\n",
    "    print(f\"Min:  {testing_rmse_adap_array.min():.6f}\")\n",
    "    print(f\"Max:  {testing_rmse_adap_array.max():.6f}\")\n",
    "    \n",
    "    print(\"ADAPTIVE TESTING MSE RESULTS:\")\n",
    "    print(\"-\" * 35)\n",
    "    print(f\"Mean: {testing_mse_adap_array.mean():.6f}\")\n",
    "    print(f\"Std:  {testing_mse_adap_array.std():.6f}\")\n",
    "    print(f\"Min:  {testing_mse_adap_array.min():.6f}\")\n",
    "    print(f\"Max:  {testing_mse_adap_array.max():.6f}\")\n",
    "    print()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dmz5uha8vap",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization plots\n",
    "if len(testing_mse_adap_list) > 0 and len(testing_mse_list) > 0:\n",
    "    testing_mse_adap_array = np.array(testing_mse_adap_list)\n",
    "    testing_mse_nonadap_array = np.array(testing_mse_list)\n",
    "    num_grids_adap_array = np.array(num_grids_adap_list)\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle('RNN-ODE: Adaptive vs Non-Adaptive Method Comparison', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Plot 1: MSE Comparison Bar Chart\n",
    "    ax1 = axes[0, 0]\n",
    "    methods = ['Non-Adaptive', 'Adaptive']\n",
    "    mse_means = [testing_mse_nonadap_array.mean(), testing_mse_adap_array.mean()]\n",
    "    mse_stds = [testing_mse_nonadap_array.std(), testing_mse_adap_array.std()]\n",
    "    colors = ['lightcoral', 'lightblue']\n",
    "    \n",
    "    bars = ax1.bar(methods, mse_means, yerr=mse_stds, capsize=5, color=colors, alpha=0.7, edgecolor='black')\n",
    "    ax1.set_ylabel('Testing MSE')\n",
    "    ax1.set_title('Average Testing MSE Comparison')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (mean, std) in enumerate(zip(mse_means, mse_stds)):\n",
    "        ax1.text(i, mean + std + 0.001, f'{mean:.5f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Plot 2: Individual Repetition Comparison\n",
    "    ax2 = axes[0, 1]\n",
    "    min_reps = min(len(testing_mse_nonadap_array), len(testing_mse_adap_array))\n",
    "    rep_indices = np.arange(1, min_reps + 1)\n",
    "    \n",
    "    ax2.plot(rep_indices, testing_mse_nonadap_array[:min_reps], 'o-', \n",
    "             color='red', linewidth=2, markersize=8, label='Non-Adaptive', alpha=0.7)\n",
    "    ax2.plot(rep_indices, testing_mse_adap_array[:min_reps], 's-', \n",
    "             color='blue', linewidth=2, markersize=8, label='Adaptive', alpha=0.7)\n",
    "    \n",
    "    ax2.set_xlabel('Repetition')\n",
    "    ax2.set_ylabel('Testing MSE')\n",
    "    ax2.set_title('MSE by Repetition')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_xticks(rep_indices)\n",
    "    \n",
    "    # Plot 3: Grid Points Comparison\n",
    "    ax3 = axes[1, 0]\n",
    "    grid_methods = ['Non-Adaptive\\n(Fixed)', 'Adaptive\\n(Average)']\n",
    "    grid_means = [num_grids, num_grids_adap_array.mean()]\n",
    "    grid_stds = [0, num_grids_adap_array.std()]\n",
    "    colors_grid = ['orange', 'green']\n",
    "    \n",
    "    bars_grid = ax3.bar(grid_methods, grid_means, yerr=grid_stds, capsize=5, \n",
    "                       color=colors_grid, alpha=0.7, edgecolor='black')\n",
    "    ax3.set_ylabel('Number of Grid Points')\n",
    "    ax3.set_title('Grid Points Comparison')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels and reduction percentage\n",
    "    reduction_pct = ((num_grids - num_grids_adap_array.mean()) / num_grids * 100)\n",
    "    ax3.text(0, grid_means[0] + 2, f'{grid_means[0]:.0f}', ha='center', va='bottom', fontweight='bold')\n",
    "    ax3.text(1, grid_means[1] + grid_stds[1] + 2, f'{grid_means[1]:.1f}\\\\n({reduction_pct:.1f}% reduction)', \n",
    "             ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Plot 4: MSE vs Grid Points Scatter\n",
    "    ax4 = axes[1, 1]\n",
    "    # Non-adaptive points (all have same grid count)\n",
    "    ax4.scatter([num_grids] * len(testing_mse_nonadap_array), testing_mse_nonadap_array,\n",
    "               color='red', s=100, alpha=0.7, label='Non-Adaptive', marker='o')\n",
    "    # Adaptive points\n",
    "    ax4.scatter(num_grids_adap_array, testing_mse_adap_array,\n",
    "               color='blue', s=100, alpha=0.7, label='Adaptive', marker='s')\n",
    "    \n",
    "    ax4.set_xlabel('Number of Grid Points')\n",
    "    ax4.set_ylabel('Testing MSE')\n",
    "    ax4.set_title('MSE vs Grid Points')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Create additional detailed comparison plot\n",
    "    fig2, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "    \n",
    "    # Box plot comparison\n",
    "    data_to_plot = [testing_mse_nonadap_array, testing_mse_adap_array]\n",
    "    box_plot = ax.boxplot(data_to_plot, labels=['Non-Adaptive', 'Adaptive'], \n",
    "                         patch_artist=True, notch=True)\n",
    "    \n",
    "    # Customize box plot colors\n",
    "    colors = ['lightcoral', 'lightblue']\n",
    "    for patch, color in zip(box_plot['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.7)\n",
    "    \n",
    "    # Add individual points\n",
    "    for i, data in enumerate(data_to_plot):\n",
    "        x = np.random.normal(i+1, 0.04, size=len(data))\n",
    "        ax.scatter(x, data, alpha=0.6, s=50, color='darkred' if i==0 else 'darkblue')\n",
    "    \n",
    "    ax.set_ylabel('Testing MSE')\n",
    "    ax.set_title('Testing MSE Distribution: Non-Adaptive vs Adaptive', fontsize=14, fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add statistics text\n",
    "    stats_text = f'''Non-Adaptive: μ={testing_mse_nonadap_array.mean():.6f}, σ={testing_mse_nonadap_array.std():.6f}\n",
    "Adaptive: μ={testing_mse_adap_array.mean():.6f}, σ={testing_mse_adap_array.std():.6f}\n",
    "Improvement: {((testing_mse_nonadap_array.mean() - testing_mse_adap_array.mean()) / testing_mse_nonadap_array.mean() * 100):.1f}%\n",
    "Grid Reduction: {((num_grids - num_grids_adap_array.mean()) / num_grids * 100):.1f}%'''\n",
    "    \n",
    "    ax.text(0.02, 0.98, stats_text, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"Insufficient data for plotting. Need both adaptive and non-adaptive results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f00b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498d9631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM One-Step Prediction Experiment (N=64)\n",
    "testing_rmse_lstm_list = []\n",
    "\n",
    "# 可复用你前面 rnn_ode 的配置；如未定义，可启用以下默认\n",
    "num_grids = 65\n",
    "verbose = 2\n",
    "n_iter = 40\n",
    "batch_size = 64\n",
    "obs_dim = 2\n",
    "n_latent = 128\n",
    "time_scale = 10\n",
    "buffer_start_steps = 2\n",
    "\n",
    "print(\"Starting LSTM One-Step Prediction Experiment...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "rep = 0\n",
    "while rep < num_rep:\n",
    "    print(f\"\\n------LSTM the {rep+1}-th replica:--------\")\n",
    "    # 数据\n",
    "    train_windows0 = train_windows0_list[rep]\n",
    "    train_ts0 = train_ts0_list[rep]\n",
    "    test_windows0 = test_windows0_list[rep]\n",
    "    test_ts0 = test_ts0_list[rep]\n",
    "\n",
    "    # 验证集（从训练中抽 50 条）\n",
    "    valid_index = np.sort(npr.choice(train_windows0.shape[0], 50, replace=False))\n",
    "    valid_windows0 = train_windows0[valid_index, :, :]\n",
    "    valid_ts0 = train_ts0[valid_index, :]\n",
    "\n",
    "    # 训练集 = 剔除验证后的其余\n",
    "    train_index = np.delete(np.arange(train_windows0.shape[0]), valid_index)\n",
    "    train_windows1 = train_windows0[train_index, :, :].clone()\n",
    "    train_ts1 = train_ts0[train_index, :].clone()\n",
    "\n",
    "    # 与 rnn_ode 一致的 buffer 时间处理（只平移时间戳）\n",
    "    if buffer_start_steps > 0:\n",
    "        deltat = train_ts1[0, -1] - train_ts1[0, -2]\n",
    "        train_ts1[:, :buffer_start_steps] = (\n",
    "            train_ts1[:, :buffer_start_steps] +\n",
    "            torch.arange(-deltat * buffer_start_steps, 0, deltat)\n",
    "        )\n",
    "\n",
    "    # DataLoader\n",
    "    train_dataset1 = MyDataset(train_windows1, train_ts1)\n",
    "    train_loader1 = DataLoader(train_dataset1, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "    input_steps1 = train_windows1.shape[1]\n",
    "\n",
    "    # 训练 LSTM\n",
    "    flag, lstm1 = train_LSTM(\n",
    "        train_loader1, input_steps1, valid_windows0, valid_ts0, num_grids,\n",
    "        verbose, n_iter=n_iter, n_latent=n_latent, obs_dim=obs_dim,\n",
    "        buffer_start_steps=buffer_start_steps, time_scale=time_scale\n",
    "    )\n",
    "\n",
    "    if not flag:\n",
    "        print(f\"Training failed for repetition {rep+1}, skipping...\")\n",
    "        continue\n",
    "    else:\n",
    "        rep += 1\n",
    "        print(f\"Training successful for repetition {rep}\")\n",
    "\n",
    "    # 测试集拟合 RMSE（与 rnn_ode 一致，fit_* 返回的是 RMSE）\n",
    "    print(\"\\nLSTM fitting error of testing data:\")\n",
    "    _, fit_L2_err_test_lstm, _ = fit_LSTM_grids(\n",
    "        lstm1, test_windows0, test_ts0, num_grids,\n",
    "        buffer_start_steps=buffer_start_steps, verbose=1,\n",
    "        n_latent=n_latent, obs_dim=obs_dim\n",
    "    )\n",
    "    testing_rmse = fit_L2_err_test_lstm.mean().item()\n",
    "    testing_rmse_lstm_list.append(testing_rmse)\n",
    "    print(f\"LSTM Testing RMSE: {testing_rmse:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LSTM EXPERIMENT COMPLETED\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Successful repetitions: {len(testing_rmse_lstm_list)}/{num_rep}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964f9031",
   "metadata": {},
   "source": [
    "# LEM Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c440c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LEM_functions import train_LEM, fit_LEM_grids\n",
    "\n",
    "testing_rmse_lem_list = []\n",
    "\n",
    "\n",
    "print(\"Starting LEM One-Step Prediction Experiment...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "testing_rmse_lem_list = []\n",
    "rep = 0\n",
    "while rep < num_rep:\n",
    "  print(f\"\\n------LEM the {rep+1}-th replica:--------\")\n",
    "  # Data for this replica\n",
    "  train_windows0 = train_windows0_list[rep]\n",
    "  train_ts0 = train_ts0_list[rep]\n",
    "  test_windows0 = test_windows0_list[rep]\n",
    "  test_ts0 = test_ts0_list[rep]\n",
    "\n",
    "  # Validation split from training\n",
    "  valid_index = np.sort(npr.choice(train_windows0.shape[0], 50, replace=False))\n",
    "  valid_windows0 = train_windows0[valid_index, :, :]\n",
    "  valid_ts0 = train_ts0[valid_index, :]\n",
    "\n",
    "  # Training set = remove validation\n",
    "  train_index = np.delete(np.arange(train_windows0.shape[0]), valid_index)\n",
    "  train_windows1 = train_windows0[train_index, :, :].clone()\n",
    "  train_ts1 = train_ts0[train_index, :].clone()\n",
    "\n",
    "  # Buffer timestamp shift (match RNN-ODE handling)\n",
    "  if buffer_start_steps > 0:\n",
    "    deltat = train_ts1[0, -1] - train_ts1[0, -2]\n",
    "    train_ts1[:, :buffer_start_steps] = (\n",
    "        train_ts1[:, :buffer_start_steps]\n",
    "        + torch.arange(-deltat * buffer_start_steps, 0, deltat)\n",
    "    )\n",
    "\n",
    "# Dataloader\n",
    "  train_dataset1 = MyDataset(train_windows1, train_ts1)\n",
    "  train_loader1 = DataLoader(train_dataset1, shuffle=True, batch_size=batch_size)\n",
    "  input_steps1 = train_windows1.shape[1]\n",
    "\n",
    "# Train LEM (defaults in LEM_functions.py: lr=0.00904, nhid=16)\n",
    "  flag, lem = train_LEM(\n",
    "    train_loader1, input_steps1, valid_windows0, valid_ts0, num_grids,\n",
    "    verbose, n_iter=n_iter, obs_dim=obs_dim,\n",
    "    buffer_start_steps=buffer_start_steps, time_scale=time_scale,\n",
    "    num_train_windows=len(train_index)\n",
    "  )\n",
    "  if not flag:\n",
    "    print(f\"Training failed for repetition {rep+1}, skipping...\")\n",
    "    continue\n",
    "  else:\n",
    "    rep += 1\n",
    "    print(f\"Training successful for repetition {rep}\")\n",
    "\n",
    "  # Test RMSE (fit metric on uniform grid)\n",
    "  print(\"\\nLEM fitting error of testing data:\")\n",
    "  _, fit_L2_err_test_lem, _ = fit_LEM_grids(\n",
    "    lem, test_windows0, test_ts0, num_grids,\n",
    "    buffer_start_steps=buffer_start_steps, verbose=1, obs_dim=obs_dim\n",
    "  )\n",
    "  testing_rmse = fit_L2_err_test_lem.mean().item()\n",
    "  testing_rmse_lem_list.append(testing_rmse)\n",
    "  print(f\"LEM Testing RMSE: {testing_rmse:.6f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"LEM EXPERIMENT COMPLETED\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Successful repetitions: {len(testing_rmse_lem_list)}/{num_rep}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8954ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.array(testing_rmse_lem_list, dtype=float)\n",
    "\n",
    "print(\"RMSE RESULTS:\")\n",
    "print(\"-----------------------------------\")\n",
    "print(f\"Mean: {rmse.mean():.6f}\")\n",
    "print(f\"Std:  {rmse.std(ddof=0):.6f}\")\n",
    "print(f\"Min:  {rmse.min():.6f}\")\n",
    "print(f\"Max:  {rmse.max():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6dd305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "dataset = \"train\" # options: \"long\", \"train\", \"test\"\n",
    "\n",
    "num_to_plot = 3 # how many sequences/windows to visualize\n",
    "indices = None # e.g., [0, 5, 10]; if None, random pick\n",
    "\n",
    "def to_numpy(x):\n",
    "  if isinstance(x, torch.Tensor):\n",
    "    return x.detach().cpu().numpy()\n",
    "  return np.asarray(x)\n",
    "\n",
    "def plot_fhn(x_seq, t_seq, title_prefix=\"\"):  \n",
    "  x = to_numpy(x_seq)\n",
    "  t = to_numpy(t_seq)\n",
    "  C = x.shape[1]\n",
    "  fig, axes = plt.subplots(2 if C >= 2 else 1, 1, figsize=(8, 4 if C == 1 else 6), sharex=True)\n",
    "  if C == 1:\n",
    "    axes = [axes]\n",
    "# v(t)\n",
    "  axes[0].plot(t, x[:, 0], color='tab:blue', lw=2)\n",
    "  axes[0].set_title(f\"{title_prefix} v(t)\")\n",
    "  axes[0].set_ylabel(\"v\")\n",
    "  axes[0].grid(alpha=0.3)\n",
    "# w(t)\n",
    "  if C >= 2:\n",
    "    axes[1].plot(t, x[:, 1], color='tab:orange', lw=2)\n",
    "    axes[1].set_title(f\"{title_prefix} w(t)\")\n",
    "    axes[1].set_xlabel(\"time\")\n",
    "    axes[1].set_ylabel(\"w\")\n",
    "    axes[1].grid(alpha=0.3)\n",
    "  else:\n",
    "    axes[0].set_xlabel(\"time\")\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "# Phase portrait if both dims present\n",
    "  if C >= 2:\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot(x[:, 0], x[:, 1], lw=2, color='tab:green')\n",
    "    plt.xlabel(\"v\")\n",
    "    plt.ylabel(\"w\")\n",
    "    plt.title(f\"{title_prefix} Phase Portrait (w vs v)\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c6b525",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fhn(train_windows0_list[0][0], train_ts0_list[0][0], \"Train window #0 -\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
